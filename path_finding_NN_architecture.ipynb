{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3420324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from NN_arch import LSTM_sMNIST, LeNet, FCP, Autoencoder\n",
    "class FourierPathNN(nn.Module):\n",
    "    def __init__(self, x1, x2, num_terms=25):\n",
    "        super(FourierPathNN, self).__init__()\n",
    "        self.num_terms = num_terms\n",
    "        self.register_buffer('x1', x1.flatten())  # Store as a constant buffer\n",
    "        self.register_buffer('x2', x2.flatten())  # Store as a constant buffer\n",
    "        \n",
    "        # Fourier coefficients for sine terms (b_n terms)\n",
    "        self.b = nn.Parameter(torch.zeros(num_terms, x1.numel()))  # Learnable sine coefficients\n",
    "\n",
    "    def forward(self, t_values):\n",
    "        \"\"\"\n",
    "        Generate weights array of t values\n",
    "        \"\"\"\n",
    "        t_values = t_values.view(-1, 1)\n",
    "        # Linear interpolation for the base term a_0\n",
    "        a_0 = (1 - t_values) * self.x1 + t_values * self.x2\n",
    "\n",
    "        sine_terms = torch.zeros_like(a_0)\n",
    "        for n in range(1, self.num_terms + 1):\n",
    "            sine_terms += self.b[n-1].view(1, -1) * torch.sin(n * torch.pi * t_values)\n",
    "        weights = a_0 + sine_terms  # Combine a_0 and sine terms\n",
    "        return weights.view(-1, *self.x1.shape)\n",
    "\n",
    "def loss_fn_simplified(weights,model,model_name, device, trainloader,b_gradients,num_terms,t_values):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \"\"\"\n",
    "    Compute the loss by injecting weights into the CNN model.\n",
    "    \"\"\"\n",
    "    set_seed(42)\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    if model_name == \"AE\": #MSE Loss for Autoencoder, cross entropy for other.\n",
    "        criterion=nn.MSELoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    Data_array=np.zeros(len(weights))\n",
    "    Loss_sum=0.0\n",
    "    #print(len(weights))\n",
    "    smoothness_loss = 0.0\n",
    "    Length=0.0\n",
    "    \n",
    "    for j in range(len(weights) - 1): # \n",
    "        smoothness_loss += torch.norm(weights[j+1] - weights[j])**2\n",
    "        Length+=torch.norm(weights[j+1] - weights[j]).item()\n",
    "    Loss_sum=0.0\n",
    "    for i in range(len(weights)): #loop through \n",
    "        \n",
    "        #weights_fc1, weights_fc2, weights_fc3 = load_and_reshape_weights(weights[i])\n",
    "        index=0\n",
    "        for param in model.parameters():\n",
    "            param.data = weights[i][index:index + param.numel()].reshape(param.shape)\n",
    "            index += param.numel()\n",
    "        model.zero_grad()\n",
    "        outputs = model(images)\n",
    "        if model_name == \"AE\":\n",
    "            loss = criterion(outputs, images)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "        total_loss+=loss\n",
    "        loss.backward() #compute gradient \n",
    "        flattened_gradients = torch.tensor([]).to(device)\n",
    "        for param in model.parameters():\n",
    "            flattened_gradients = torch.cat((flattened_gradients, param.grad.flatten()))\n",
    "        for n in range(num_terms):\n",
    "            b_gradients[n]+=flattened_gradients*torch.sin((n+1)*np.pi*t_values[i])\n",
    "        Data_array[i]=loss.item()       \n",
    "    return total_loss,Data_array,Length,b_gradients,0.001*smoothness_loss\n",
    "\n",
    "\n",
    "\n",
    "def train_fourier_nn_simplified(path_model,model, model_name, images, labels, num_terms, num_steps=100, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optim.Adam(path_model.parameters(), lr=lr) #Can also be SGD or rmsprop\n",
    "    t_values = torch.linspace(0, 1, 51).unsqueeze(1).to(device)  # 50 points between t= 0 and 1\n",
    "    Min_Loss=None\n",
    "    for step in range(num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        path_weights = path_model(t_values)  # Generate weights with time t along the opt path.\n",
    "        b_gradients=torch.zeros_like(path_model.b)\n",
    "        loss,Data_array,L,b_gradients,smoothness_loss = loss_fn_simplified(path_weights,model,model_name, device, trainloader,b_gradients,num_terms,t_values)\n",
    "        smoothness_loss.backward()\n",
    "        path_model.b.grad.add_(b_gradients)\n",
    "        optimizer.step()\n",
    "        if Min_Loss is None or Min_Loss > loss:\n",
    "            Min_array=Data_array\n",
    "            Min_Loss=loss\n",
    "            Min_Length=L\n",
    "    print(f\"Loss: {loss:.6f}\",\"Length:\", L)\n",
    "    return Min_array,Min_Length\n",
    "\n",
    "def main_simplified(x1,x2,model_name,data_set):\n",
    "    # Dataset Preparation\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if model_name == \"AE\":\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.view(-1))]) \n",
    "    else: \n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    if data_set == \"Test\":\n",
    "        trainset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "        trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "    else: \n",
    "        trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        break\n",
    "    num_terms=10 #10 terms in truncated Fourier series\n",
    "    \n",
    "    #Generate initial path\n",
    "    fourier_nn = FourierPathNN(x1, x2, num_terms=num_terms).to(device)\n",
    "\n",
    "    # Landscape used for pathfinding\n",
    "    if model_name == \"LN\" :\n",
    "        model = LeNet()\n",
    "    elif model_name == \"FCP\" :\n",
    "        model = FCP()\n",
    "    elif model_name == \"AE\" :\n",
    "        model = Autoencoder()\n",
    "    elif model_name == \"LSTM\" :\n",
    "        model=LSTM_sMNIST()\n",
    "    # Train the FourierPathNN\n",
    "    Min_path,L=train_fourier_nn_simplified(fourier_nn,model,model_name,images, labels,num_terms)\n",
    "    return Min_path,L\n",
    "\n",
    "model_name_array=[\"FCP\",\"LN\",\"AE\",\"LSTM\"] #Select which architecture\n",
    "data_set_array=[\"Test\",\"Train\"]\n",
    "model_name=model_name_array\n",
    "if model_name == \"FCP\":\n",
    "    x_array=np.load(\"FC_BFGS_Training_best48_weights.npy\")\n",
    "if model_name == \"LN\":\n",
    "    x_array=np.load(\"LN_BFGS_Training_best48_weights.npy\")\n",
    "if model_name == \"AE\":\n",
    "    x_array=np.load(\"AE_BFGS_Training_best48_weights.npy\")\n",
    "if model_name == \"LSTM\":\n",
    "    x_array=np.load(\"LSTM_BFGS_Training_best48_weights.npy\")\n",
    "\n",
    "#pick start and end points \n",
    "x1=x_array[1]\n",
    "x2=x_array[2]\n",
    "main_simplified(x1,x2,model_name,data_set_array[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
