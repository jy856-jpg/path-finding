{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3420324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 475.563049 Length: 68.32694578170776\n",
      "Loss: 357.752014 Length: 68.8485255241394\n",
      "Loss: 264.756348 Length: 69.38675284385681\n",
      "Loss: 196.999329 Length: 70.05835568904877\n",
      "Loss: 150.284332 Length: 70.8364908695221\n",
      "Loss: 119.987793 Length: 71.72914159297943\n",
      "Loss: 100.173187 Length: 72.67347288131714\n",
      "Loss: 86.302536 Length: 73.6369047164917\n",
      "Loss: 76.050720 Length: 74.61664998531342\n",
      "Loss: 68.294945 Length: 75.59973192214966\n",
      "Loss: 62.156147 Length: 76.56736087799072\n",
      "Loss: 56.861256 Length: 77.51413536071777\n",
      "Loss: 52.047848 Length: 78.4438978433609\n",
      "Loss: 47.754478 Length: 79.3578907251358\n",
      "Loss: 44.029400 Length: 80.25340187549591\n",
      "Loss: 40.807632 Length: 81.12836050987244\n",
      "Loss: 37.953770 Length: 81.98033511638641\n",
      "Loss: 35.342098 Length: 82.8065196275711\n",
      "Loss: 32.940788 Length: 83.60471057891846\n",
      "Loss: 30.796051 Length: 84.37524616718292\n",
      "Loss: 28.948427 Length: 85.11936092376709\n",
      "Loss: 27.379807 Length: 85.83615911006927\n",
      "Loss: 26.007095 Length: 86.5222897529602\n",
      "Loss: 24.739134 Length: 87.17441773414612\n",
      "Loss: 23.537537 Length: 87.79161977767944\n",
      "Loss: 22.419771 Length: 88.3749235868454\n",
      "Loss: 21.408371 Length: 88.92556822299957\n",
      "Loss: 20.505733 Length: 89.44545483589172\n",
      "Loss: 19.704773 Length: 89.93721985816956\n",
      "Loss: 18.998123 Length: 90.404252409935\n",
      "Loss: 18.379276 Length: 90.8499447107315\n",
      "Loss: 17.841488 Length: 91.27688479423523\n",
      "Loss: 17.368490 Length: 91.68658101558685\n",
      "Loss: 16.933044 Length: 92.07988262176514\n",
      "Loss: 16.507578 Length: 92.45726025104523\n",
      "Loss: 16.076134 Length: 92.81904947757721\n",
      "Loss: 15.637723 Length: 93.16575133800507\n",
      "Loss: 15.201828 Length: 93.49809062480927\n",
      "Loss: 14.781313 Length: 93.81677556037903\n",
      "Loss: 14.385474 Length: 94.12228059768677\n",
      "Loss: 14.017313 Length: 94.41465616226196\n",
      "Loss: 13.675282 Length: 94.69386219978333\n",
      "Loss: 13.355735 Length: 94.95996451377869\n",
      "Loss: 13.055119 Length: 95.2132135629654\n",
      "Loss: 12.770553 Length: 95.45395028591156\n",
      "Loss: 12.499936 Length: 95.68264484405518\n",
      "Loss: 12.241899 Length: 95.89994478225708\n",
      "Loss: 11.995626 Length: 96.10663914680481\n",
      "Loss: 11.761137 Length: 96.30356097221375\n",
      "Loss: 11.538278 Length: 96.49158072471619\n",
      "Loss: 11.326538 Length: 96.67160713672638\n",
      "Loss: 11.125086 Length: 96.8445256948471\n",
      "Loss: 10.932686 Length: 97.01113617420197\n",
      "Loss: 10.748106 Length: 97.17211973667145\n",
      "Loss: 10.570236 Length: 97.32798671722412\n",
      "Loss: 10.398271 Length: 97.47913765907288\n",
      "Loss: 10.231751 Length: 97.6258385181427\n",
      "Loss: 10.070479 Length: 97.76826024055481\n",
      "Loss: 9.914408 Length: 97.90659081935883\n",
      "Loss: 9.763518 Length: 98.04107880592346\n",
      "Loss: 9.617689 Length: 98.1720312833786\n",
      "Loss: 9.476651 Length: 98.29979074001312\n",
      "Loss: 9.340015 Length: 98.42480301856995\n",
      "Loss: 9.207424 Length: 98.54753696918488\n",
      "Loss: 9.078628 Length: 98.66849136352539\n",
      "Loss: 8.953484 Length: 98.7881371974945\n",
      "Loss: 8.831869 Length: 98.90687084197998\n",
      "Loss: 8.713630 Length: 99.02500760555267\n",
      "Loss: 8.598625 Length: 99.14271628856659\n",
      "Loss: 8.486776 Length: 99.26007580757141\n",
      "Loss: 8.378057 Length: 99.37706422805786\n",
      "Loss: 8.272436 Length: 99.49360346794128\n",
      "Loss: 8.169823 Length: 99.60962080955505\n",
      "Loss: 8.070007 Length: 99.72505795955658\n",
      "Loss: 7.972716 Length: 99.8399064540863\n",
      "Loss: 7.877686 Length: 99.9541791677475\n",
      "Loss: 7.784754 Length: 100.06792175769806\n",
      "Loss: 7.693862 Length: 100.18117439746857\n",
      "Loss: 7.605004 Length: 100.29395067691803\n",
      "Loss: 7.518146 Length: 100.40622925758362\n",
      "Loss: 7.433204 Length: 100.51792693138123\n",
      "Loss: 7.350056 Length: 100.62895917892456\n",
      "Loss: 7.268604 Length: 100.73922395706177\n",
      "Loss: 7.188810 Length: 100.84863519668579\n",
      "Loss: 7.110664 Length: 100.95711839199066\n",
      "Loss: 7.034163 Length: 101.06463849544525\n",
      "Loss: 6.959276 Length: 101.17118525505066\n",
      "Loss: 6.885935 Length: 101.27677571773529\n",
      "Loss: 6.814064 Length: 101.38144958019257\n",
      "Loss: 6.743589 Length: 101.48525786399841\n",
      "Loss: 6.674449 Length: 101.58826553821564\n",
      "Loss: 6.606593 Length: 101.69054543972015\n",
      "Loss: 6.539989 Length: 101.79216802120209\n",
      "Loss: 6.474615 Length: 101.893195271492\n",
      "Loss: 6.410447 Length: 101.99367082118988\n",
      "Loss: 6.347453 Length: 102.09364235401154\n",
      "Loss: 6.285591 Length: 102.19313979148865\n",
      "Loss: 6.224808 Length: 102.29217648506165\n",
      "Loss: 6.165056 Length: 102.39078140258789\n",
      "Loss: 6.106301 Length: 102.4889509677887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.08659233e-08, 4.49384970e-07, 4.12673435e-05, 7.63868215e-04,\n",
       "        2.95695895e-03, 6.45107450e-03, 1.08467238e-02, 1.59296021e-02,\n",
       "        2.21172329e-02, 3.06826755e-02, 4.29794565e-02, 5.88968471e-02,\n",
       "        7.62456506e-02, 9.43317041e-02, 1.13942496e-01, 1.34630710e-01,\n",
       "        1.54949337e-01, 1.76157534e-01, 2.02274844e-01, 2.33991459e-01,\n",
       "        2.68712372e-01, 3.02353710e-01, 3.32254380e-01, 3.54883075e-01,\n",
       "        3.72154951e-01, 3.76967698e-01, 3.57264251e-01, 3.24091822e-01,\n",
       "        2.90929466e-01, 2.60786235e-01, 2.31080890e-01, 2.01969817e-01,\n",
       "        1.77981094e-01, 1.58683077e-01, 1.41387358e-01, 1.24401800e-01,\n",
       "        1.07049510e-01, 8.97246450e-02, 7.25202486e-02, 5.60392402e-02,\n",
       "        4.13657390e-02, 2.97917333e-02, 2.13797204e-02, 1.52749233e-02,\n",
       "        1.02849100e-02, 5.86445164e-03, 2.36677355e-03, 5.19371824e-04,\n",
       "        2.80024105e-05, 3.22261769e-07, 1.09354632e-08]),\n",
       " 102.4889509677887)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from NN_arch import LSTM_sMNIST, LeNet, FCP, Autoencoder\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "class FourierPathNN(nn.Module):\n",
    "    def __init__(self, x1, x2, num_terms=25):\n",
    "        super(FourierPathNN, self).__init__()\n",
    "        self.num_terms = num_terms\n",
    "        self.register_buffer('x1', x1.flatten())  # Store as a constant buffer\n",
    "        self.register_buffer('x2', x2.flatten())  # Store as a constant buffer\n",
    "        \n",
    "        # Fourier coefficients for sine terms (b_n terms)\n",
    "        self.b = nn.Parameter(torch.zeros(num_terms, x1.numel()))  # Learnable sine coefficients\n",
    "\n",
    "    def forward(self, t_values):\n",
    "        \"\"\"\n",
    "        Generate weights array of t values\n",
    "        \"\"\"\n",
    "        t_values = t_values.view(-1, 1)\n",
    "        # Linear interpolation for the base term a_0\n",
    "        a_0 = (1 - t_values) * self.x1 + t_values * self.x2\n",
    "\n",
    "        sine_terms = torch.zeros_like(a_0)\n",
    "        for n in range(1, self.num_terms + 1):\n",
    "            sine_terms += self.b[n-1].view(1, -1) * torch.sin(n * torch.pi * t_values)\n",
    "        weights = a_0 + sine_terms  # Combine a_0 and sine terms\n",
    "        return weights.view(-1, *self.x1.shape)\n",
    "\n",
    "def loss_fn_simplified(weights,model,model_name, device, images, labels,b_gradients,num_terms,t_values):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \"\"\"\n",
    "    Compute the loss by injecting weights into the CNN model.\n",
    "    \"\"\"\n",
    "    set_seed(42)\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    if model_name == \"AE\": #MSE Loss for Autoencoder, cross entropy for other.\n",
    "        criterion=nn.MSELoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    Data_array=np.zeros(len(weights))\n",
    "    Loss_sum=0.0\n",
    "    #print(len(weights))\n",
    "    smoothness_loss = 0.0\n",
    "    Length=0.0\n",
    "    \n",
    "    for j in range(len(weights) - 1): # \n",
    "        smoothness_loss += torch.norm(weights[j+1] - weights[j])**2\n",
    "        Length+=torch.norm(weights[j+1] - weights[j]).item()\n",
    "    Loss_sum=0.0\n",
    "    for i in range(len(weights)): #loop through \n",
    "        \n",
    "        #weights_fc1, weights_fc2, weights_fc3 = load_and_reshape_weights(weights[i])\n",
    "        index=0\n",
    "        for param in model.parameters():\n",
    "            param.data = weights[i][index:index + param.numel()].reshape(param.shape)\n",
    "            index += param.numel()\n",
    "        model.zero_grad()\n",
    "        outputs = model(images)\n",
    "        if model_name == \"AE\":\n",
    "            loss = criterion(outputs, images)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "                \n",
    "        total_loss+=loss\n",
    "        loss.backward() #compute gradient \n",
    "        flattened_gradients = torch.tensor([]).to(device)\n",
    "        for param in model.parameters():\n",
    "            flattened_gradients = torch.cat((flattened_gradients, param.grad.flatten()))\n",
    "        for n in range(num_terms):\n",
    "            b_gradients[n]+=flattened_gradients*torch.sin((n+1)*np.pi*t_values[i])\n",
    "        Data_array[i]=loss.item()       \n",
    "    return total_loss,Data_array,Length,b_gradients,0.001*smoothness_loss\n",
    "\n",
    "\n",
    "\n",
    "def train_fourier_nn_simplified(path_model,model, model_name, images, labels, num_terms, num_steps=100, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer = optim.Adam(path_model.parameters(), lr=lr) #Can also be SGD or rmsprop\n",
    "    t_values = torch.linspace(0, 1, 51).unsqueeze(1).to(device)  # 50 points between t= 0 and 1\n",
    "    Min_Loss=None\n",
    "    for step in range(num_steps):\n",
    "        optimizer.zero_grad()\n",
    "        path_weights = path_model(t_values)  # Generate weights with time t along the opt path.\n",
    "        b_gradients=torch.zeros_like(path_model.b)\n",
    "        loss,Data_array,L,b_gradients,smoothness_loss = loss_fn_simplified(path_weights,model,model_name, device,images, labels,b_gradients,num_terms,t_values)\n",
    "        smoothness_loss.backward()\n",
    "        path_model.b.grad.add_(b_gradients)\n",
    "        optimizer.step()\n",
    "        if Min_Loss is None or Min_Loss > loss:\n",
    "            Min_array=Data_array\n",
    "            Min_Loss=loss\n",
    "            Min_Length=L\n",
    "        print(f\"Loss: {loss:.6f}\",\"Length:\", L)\n",
    "    return Min_array,Min_Length\n",
    "\n",
    "def main_simplified(x1,x2,model_name,data_set):\n",
    "    # Dataset Preparation\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if model_name == \"AE\":\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x.view(-1))]) \n",
    "    else: \n",
    "        transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    if data_set == \"Test\":\n",
    "        trainset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "        trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "    else: \n",
    "        trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        trainloader = DataLoader(trainset, batch_size=len(trainset), shuffle=True)\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        break\n",
    "    num_terms=10 #10 terms in truncated Fourier series\n",
    "    \n",
    "    #Generate initial path\n",
    "    fourier_nn = FourierPathNN(x1, x2, num_terms=num_terms).to(device)\n",
    "\n",
    "    # Landscape used for pathfinding\n",
    "    if model_name == \"LN\" :\n",
    "        model = LeNet()\n",
    "    elif model_name == \"FCP\" :\n",
    "        model = FCP()\n",
    "    elif model_name == \"AE\" :\n",
    "        model = Autoencoder()\n",
    "    elif model_name == \"LSTM\" :\n",
    "        model=LSTM_sMNIST()\n",
    "    # Train the FourierPathNN\n",
    "    Min_path,L=train_fourier_nn_simplified(fourier_nn,model,model_name,images, labels,num_terms)\n",
    "    return Min_path,L\n",
    "\n",
    "model_name_array=[\"FCP\",\"LN\",\"AE\",\"LSTM\"] #Select which architecture\n",
    "data_set_array=[\"Test\",\"Train\"]\n",
    "model_name=model_name_array[0]\n",
    "if model_name == \"FCP\":\n",
    "    x_array=np.load(\"FC_BFGS_Training_best48_weights.npy\")\n",
    "if model_name == \"LN\":\n",
    "    x_array=np.load(\"LN_BFGS_Training_best48_weights.npy\")\n",
    "if model_name == \"AE\":\n",
    "    x_array=np.load(\"AE_BFGS_Training_best48_weights.npy\")\n",
    "if model_name == \"LSTM\":\n",
    "    x_array=np.load(\"LSTM_BFGS_Training_best48_weights.npy\")\n",
    "set_seed(0)\n",
    "#pick start and end points \n",
    "x1=torch.from_numpy(x_array[0])\n",
    "x2=torch.from_numpy(x_array[1])\n",
    "main_simplified(x1,x2,model_name,data_set_array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378508dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01798414 -0.02193643 -0.03122183 ...  0.8760873  -1.2382613\n",
      " -0.14082627]\n"
     ]
    }
   ],
   "source": [
    "print(x_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f06c1a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.18\n",
      "PyTorch: 2.8.0+cpu\n",
      "torchvision: 0.23.0+cpu\n",
      "NumPy: 2.1.2\n",
      "CUDA: None\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4396e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyTorch)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
